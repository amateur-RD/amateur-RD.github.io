<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Young Blog</title>
  
  <subtitle>Young Cheng</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://amateur-rd.github.io/"/>
  <updated>2018-07-17T14:14:17.926Z</updated>
  <id>https://amateur-rd.github.io/</id>
  
  <author>
    <name>[object Object]</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>hadoop案例测试——pi值、wordcount函数，hadoop不支持本地库问题</title>
    <link href="https://amateur-rd.github.io/2018/07/17/hadoop-demo/"/>
    <id>https://amateur-rd.github.io/2018/07/17/hadoop-demo/</id>
    <published>2018-07-17T14:08:06.951Z</published>
    <updated>2018-07-17T14:14:17.926Z</updated>
    
    <content type="html"><![CDATA[<p>前言：本文案例测试所需环境都是在前面几篇blog的基础上进行的，具体内容请查看：<br><a href="http://blog.csdn.net/u012829611/article/details/77678609" target="_blank" rel="noopener">http://blog.csdn.net/u012829611/article/details/77678609</a><br><a href="http://blog.csdn.net/u012829611/article/details/77651855" target="_blank" rel="noopener">http://blog.csdn.net/u012829611/article/details/77651855</a></p><h2 id="1-使用hadoop估算pi的值"><a href="#1-使用hadoop估算pi的值" class="headerlink" title="1.使用hadoop估算pi的值"></a>1.使用hadoop估算pi的值</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.7.3]# yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar pi 5 10</span><br></pre></td></tr></table></figure><p><strong>注</strong>：命令中，“5”表示map进行5次，“10”表示每次map投掷10次（相当于扔飞镖10次计算出pi的值）</p><p><img src="http://img.blog.csdn.net/20170829155150291?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>最终计算结果：</p><p><img src="http://img.blog.csdn.net/20170829155158660?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><h2 id="2-使用mapreduce中wordcount函数计算-input目录下test文件中单词出现的次数，结果输出到-output目录下"><a href="#2-使用mapreduce中wordcount函数计算-input目录下test文件中单词出现的次数，结果输出到-output目录下" class="headerlink" title="2.使用mapreduce中wordcount函数计算/input目录下test文件中单词出现的次数，结果输出到/output目录下"></a>2.使用mapreduce中wordcount函数计算/input目录下test文件中单词出现的次数，结果输出到/output目录下</h2><p>//hdfs上创建文件夹input</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.7.3]# hdfs dfs -mkdir /input</span><br><span class="line">[hadoop@localhost hadoop-2.7.3]# hdfs dfs -ls /</span><br></pre></td></tr></table></figure><p>//新建test文件，输入一些字符串</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.7.3]# vim test</span><br></pre></td></tr></table></figure><p>//将test文件put到hdfs的input目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.7.3]# hdfs dfs -put test /input</span><br></pre></td></tr></table></figure><p>//执行命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.7.3]# yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount /input/test /output</span><br></pre></td></tr></table></figure><p><img src="http://img.blog.csdn.net/20170829155358720?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>//查看output目录下的文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.7.3]# hdfs dfs -ls /output</span><br></pre></td></tr></table></figure><p><img src="http://img.blog.csdn.net/20170829155515758?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>//查看统计结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost hadoop-2.7.3]# hdfs dfs -cat /output/part-r-00000</span><br></pre></td></tr></table></figure><p><img src="http://img.blog.csdn.net/20170829155537720?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>附</strong>：<br>①hdfs dfs -rm -r /output                     //删除hdfs上的output文件夹</p><hr><h2 id="关于hadoop不支持本地库问题"><a href="#关于hadoop不支持本地库问题" class="headerlink" title="关于hadoop不支持本地库问题"></a>关于hadoop不支持本地库问题</h2><p>问题描述：hadoop安装完后，使用”hadoop checknative”命令查看是否支持本地库时，发现不支持hadoop、zlib、snappy等一些本地库。</p><p>解决方法：执行以下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost bin]# export HADOOP_OPTS=&quot;-Djava.library.path=./../lib/native/&quot;</span><br></pre></td></tr></table></figure><p>参考文档：<br><a href="http://blog.csdn.net/ligt0610/article/details/47757013" target="_blank" rel="noopener">http://blog.csdn.net/ligt0610/article/details/47757013</a><br><a href="https://zhidao.baidu.com/question/1766673293716469500.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/1766673293716469500.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言：本文案例测试所需环境都是在前面几篇blog的基础上进行的，具体内容请查看：&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/u012829611/article/details/77678609&quot; target=&quot;_blank&quot; rel=&quot;noope
      
    
    </summary>
    
      <category term="BigData" scheme="https://amateur-rd.github.io/categories/BigData/"/>
    
    
      <category term="Hadoop" scheme="https://amateur-rd.github.io/tags/Hadoop/"/>
    
      <category term="MapReduce" scheme="https://amateur-rd.github.io/tags/MapReduce/"/>
    
      <category term="wordcount" scheme="https://amateur-rd.github.io/tags/wordcount/"/>
    
  </entry>
  
  <entry>
    <title>编译spark源码的方法，及编译、案例测试问题总结</title>
    <link href="https://amateur-rd.github.io/2018/07/16/spark-build/"/>
    <id>https://amateur-rd.github.io/2018/07/16/spark-build/</id>
    <published>2018-07-16T14:00:29.275Z</published>
    <updated>2018-07-17T13:57:48.443Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、编译spark方法"><a href="#一、编译spark方法" class="headerlink" title="一、编译spark方法"></a>一、编译spark方法</h2><p>1.编译环境<br>首先，需要安装jdk、maven，相关安装教程请参考：<a href="http://blog.csdn.net/u012829611/article/details/77651855" target="_blank" rel="noopener">http://blog.csdn.net/u012829611/article/details/77651855</a><br><a href="http://blog.csdn.net/u012829611/article/details/77678609" target="_blank" rel="noopener">http://blog.csdn.net/u012829611/article/details/77678609</a><br>笔者安装的jdk1.7、maven3.3.9.<br>然后，在官网下载spark源码（<a href="http://spark.apache.org/downloads.html），我这里选择的版本是spark-1.6.2.tgz" target="_blank" rel="noopener">http://spark.apache.org/downloads.html），我这里选择的版本是spark-1.6.2.tgz</a><br>把源码包解压：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost soft-cy]# tar -zxvf spark-1.6.2.tgz</span><br><span class="line">[root@localhost soft-cy]# cd spark-1.6.2</span><br></pre></td></tr></table></figure><p>2.两种编译方法<br>①用build/mvn 来编译（采用） </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost spark-1.6.2]# build/mvn -Pyarn -Phadoop-2.7 -Dhadoop.version=2.7.3 -DskipTests clean package</span><br></pre></td></tr></table></figure><p>（-Pyarn 提供yarn支持 ，—Phadoop-2.7 提供Hadoop支持，并且指定hadoop的版本2.7.3）<br><img src="http://img.blog.csdn.net/20170901154034940?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>编译完成后，你会发现在assembly/target/scala-2.10目录下面有一个spark-assembly-1.6.2-hadoop2.7.3.jar包，这个就是编译的结果。</p><p>②用make-distributed 脚本来编译 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost spark-1.6.2]# ./make-distribution.sh --name spark-1.6.2 --skip-java-test --tgz -Pyarn -Dhadoop.version=2.7.3 -Phive -Phive-thriftserver</span><br></pre></td></tr></table></figure><p>编译完源代码后，虽然直接用编译后的目录再加以配置就可以运行spark，但是这时目录很庞大，部署起来很不方便，所以需要生成部署包。生成在部署包位于根目录下，文件名类似于 spark–bin-spark-1.6.2.tgz 。</p><h2 id="二、编译遇到问题总结"><a href="#二、编译遇到问题总结" class="headerlink" title="二、编译遇到问题总结"></a>二、编译遇到问题总结</h2><p>1.依赖包下载不下来的问题<br>如下图，显示一些相关依赖包下载不下来，即downloading过程中停止<br><img src="http://img.blog.csdn.net/20170901154201422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>【解决方法】：手动下载相关依赖包，并放到指定目录下即可。<br>以上图中第一个依赖包为例Downloading：<a href="https://repo1.maven.org/maven2/org/apache/curator/curator-test/2.4.0/curator-test-2.4.0.jar" target="_blank" rel="noopener">https://repo1.maven.org/maven2/org/apache/curator/curator-test/2.4.0/curator-test-2.4.0.jar</a><br>具体下载方法如下：从上面下载链接中可以看出依赖包存放的目录（/root/.m2/repository/org/apache/curator/curator-test/2.4.0），上面链接中加粗的部分。因此，直接cd到相应目录，wget即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# cd /root/.m2/repository/org/apache/curator/curator-test/2.4.0</span><br><span class="line">[root@localhost 2.4.0]# wget https://repo1.maven.org/maven2/org/apache/curator/curator-test/2.4.0/curator-test-2.4.0.jar</span><br></pre></td></tr></table></figure><p><strong>注</strong>：用maven进行编译时，下载的相关依赖包都放在maven库中，maven库的目录为：/root/.m2/repository</p><p>2.通过编辑pom.xml文件，注释相应的module，可以编译时跳过相应的Project，这样可以方便调试。</p><p><img src="http://img.blog.csdn.net/20170901154321442?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>3.使用第二种方法编译时，会报如下错：</p><p><img src="http://img.blog.csdn.net/20170901154336182?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>解决方法：编辑make-distribution.sh文件，注释掉下图中阴影部分，保存即可。</p><p><img src="http://img.blog.csdn.net/20170901154346881?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>参考文档：<br><a href="http://blog.csdn.net/yanran1991326/article/details/46506595" target="_blank" rel="noopener">http://blog.csdn.net/yanran1991326/article/details/46506595</a><br><a href="http://blog.csdn.net/ouyangyanlan/article/details/52355350" target="_blank" rel="noopener">http://blog.csdn.net/ouyangyanlan/article/details/52355350</a></p><h2 id="三、案例测试问题"><a href="#三、案例测试问题" class="headerlink" title="三、案例测试问题"></a>三、案例测试问题</h2><p>spark编译成功后，cd到 spark1.6.2/bin 目录下，运行 spark-shell 命令启动spark，进入scala命令模式。运行案例测试，输入 sc.parallelize(1 to 1000).count() 命令，会报下图中错误：</p><p><img src="http://img.blog.csdn.net/20170901154511668?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 spark-1.6.2]# cd bin/</span><br><span class="line">[root@localhost bin]# spark-shell</span><br><span class="line">scala&gt; sc.parallelize(1 to 1000).count()</span><br></pre></td></tr></table></figure></p><p>错误信息：“org.xerial.snappy.SnappyError: [FAILED_TO_LOAD_NATIVE_LIBRARY] no native library is found for os.name=Linux and os.arch=sw”。表示：snappy不支持Linux-sw操作系统。<br>解决方法：spark默认的解压缩工具为snappy，查看官网及github上，发现spark可选解压缩工具有三种lz4、lzf、snappy，于是可将spark默认的解压缩工具改为lzf。<br>官网：<a href="https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties</a><br>github：<a href="https://github.com/xerial/snappy-java/issues/178" target="_blank" rel="noopener">https://github.com/xerial/snappy-java/issues/178</a></p><p><img src="http://img.blog.csdn.net/20170901154537249?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>具体执行过程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 spark-1.6.2]# cd conf/</span><br><span class="line">[root@node1 conf]# cp spark-defaults.conf.template spark-defaults.conf</span><br><span class="line">[root@node1 conf]# vim spark-defaults.conf</span><br></pre></td></tr></table></figure><p>在最后添加命令 <code>spark.io.compression.codec         lzf</code></p><p><img src="http://img.blog.csdn.net/20170901154552027?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>添加命令后，保存退出，重新启动spark，运行案例测试，结果显示成功。</p><p>案例1：统计整数个数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost bin]# spark-shell</span><br></pre></td></tr></table></figure><p><img src="http://img.blog.csdn.net/20170901172645841?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; sc.parallelize(1 to 1000).count()</span><br></pre></td></tr></table></figure><p>运行可以看到，结果显示 res0: Long = 1000         表示成功！</p><p><img src="http://img.blog.csdn.net/20170901154649633?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>案例2：计算pi的值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost bin]# run-example SparkPi</span><br></pre></td></tr></table></figure><p><img src="http://img.blog.csdn.net/20170901154730977?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>运行可以看到，结果显示 Pi is roughly 3.14552            表示成功！</p><p><img src="http://img.blog.csdn.net/20170901154738840?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><blockquote><p>参考文档：<a href="https://github.com/xerial/snappy-java/issues/178" target="_blank" rel="noopener">https://github.com/xerial/snappy-java/issues/178</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、编译spark方法&quot;&gt;&lt;a href=&quot;#一、编译spark方法&quot; class=&quot;headerlink&quot; title=&quot;一、编译spark方法&quot;&gt;&lt;/a&gt;一、编译spark方法&lt;/h2&gt;&lt;p&gt;1.编译环境&lt;br&gt;首先，需要安装jdk、maven，相关安装教程请
      
    
    </summary>
    
      <category term="BigData" scheme="https://amateur-rd.github.io/categories/BigData/"/>
    
    
      <category term="spark" scheme="https://amateur-rd.github.io/tags/spark/"/>
    
      <category term="spark源码编译" scheme="https://amateur-rd.github.io/tags/spark%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"/>
    
      <category term="sparkpi" scheme="https://amateur-rd.github.io/tags/sparkpi/"/>
    
  </entry>
  
  <entry>
    <title>git命令上传本地文件到GitHub</title>
    <link href="https://amateur-rd.github.io/2018/07/15/git/"/>
    <id>https://amateur-rd.github.io/2018/07/15/git/</id>
    <published>2018-07-15T09:32:40.736Z</published>
    <updated>2018-07-15T10:13:35.829Z</updated>
    
    <content type="html"><![CDATA[<h1 id="git命令上传本地文件到GitHub"><a href="#git命令上传本地文件到GitHub" class="headerlink" title="git命令上传本地文件到GitHub"></a>git命令上传本地文件到GitHub</h1><h4 id="1-下载git工具"><a href="#1-下载git工具" class="headerlink" title="1.下载git工具"></a>1.下载<a href="https://git-scm.com/downloads" target="_blank" rel="noopener">git工具</a></h4><h4 id="2-绑定用户"><a href="#2-绑定用户" class="headerlink" title="2.绑定用户"></a>2.绑定用户</h4><ul><li><p>启动gitBash<br><img src="https://img-blog.csdn.net/20180406165400726?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4Mjk2MTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="gitBash"></p></li><li><p>绑定用户名和邮箱</p><blockquote><p>在打开的GIt Bash中输入以下命令（用户和邮箱为你github注册的账号和邮箱）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global user.name &quot;amateur-RD&quot;</span><br><span class="line">$ git config --global user.email &quot;chengy2016@163.com&quot;</span><br></pre></td></tr></table></figure></blockquote></li></ul><h4 id="3-上传本地文件到GitHub"><a href="#3-上传本地文件到GitHub" class="headerlink" title="3.上传本地文件到GitHub"></a>3.上传本地文件到GitHub</h4><ul><li>建立本地仓库</li></ul><blockquote><p>进入要上传到GitHub仓库的本地项目所在目录</p></blockquote><p><img src="https://img-blog.csdn.net/20180406170604597?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4Mjk2MTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="cd到本地项目目录"></p><ul><li><p>执行命令：<code>git init</code><br><img src="https://img-blog.csdn.net/20180406171010536?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4Mjk2MTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="git init"></p></li><li><p>执行命令：<code>git add .</code></p><blockquote><p>将所有文件添加到仓库，其中 . 号表示所有文件，也可以用文件名来指定某个文件。</p></blockquote></li></ul><p><img src="https://img-blog.csdn.net/20180406171246994?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4Mjk2MTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="git add"></p><ul><li>执行命令：<code>git commit -m &quot;提交文件&quot;</code><blockquote><p>双引号内是提交注释。</p></blockquote></li></ul><p><img src="https://img-blog.csdn.net/20180406171534339?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4Mjk2MTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="git commit"></p><ul><li>执行命令：<code>git remote add origin https://github.com/amateur-RD/Lab-Service-MS.git</code></li></ul><p><img src="https://img-blog.csdn.net/20180406171839778?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4Mjk2MTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="git remote"></p><ul><li>执行命令：<code>git pull --rebase origin master</code></li></ul><blockquote><p>进行代码合并【注：pull=fetch+merge】</p></blockquote><p><img src="https://img-blog.csdn.net/20180406172005642?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4Mjk2MTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="git pull"></p><ul><li>执行命令：<code>git push -u origin master</code></li></ul><blockquote><p>上传本地文件</p></blockquote><p><img src="https://img-blog.csdn.net/20180406172149432?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4Mjk2MTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="git push"></p><ul><li>完成，到GitHub上即可看到相应文件</li></ul><p><img src="https://img-blog.csdn.net/20180406172320538?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4Mjk2MTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="GitHub"></p><p>参考文章：<a href="https://blog.csdn.net/pql925/article/details/72772660" target="_blank" rel="noopener">https://blog.csdn.net/pql925/article/details/72772660</a></p><blockquote><p> 说明：笔者<strong><a href="https://github.com/amateur-RD" target="_blank" rel="noopener">GitHub</a></strong>，欢迎follow。感谢！！！</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;git命令上传本地文件到GitHub&quot;&gt;&lt;a href=&quot;#git命令上传本地文件到GitHub&quot; class=&quot;headerlink&quot; title=&quot;git命令上传本地文件到GitHub&quot;&gt;&lt;/a&gt;git命令上传本地文件到GitHub&lt;/h1&gt;&lt;h4 id=&quot;1
      
    
    </summary>
    
      <category term="Linux" scheme="https://amateur-rd.github.io/categories/Linux/"/>
    
    
      <category term="git" scheme="https://amateur-rd.github.io/tags/git/"/>
    
      <category term="github" scheme="https://amateur-rd.github.io/tags/github/"/>
    
      <category term="linux" scheme="https://amateur-rd.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>noVNC实现远程访问Docker容器桌面</title>
    <link href="https://amateur-rd.github.io/2018/07/15/noVNC-Docker/"/>
    <id>https://amateur-rd.github.io/2018/07/15/noVNC-Docker/</id>
    <published>2018-07-15T03:48:43.768Z</published>
    <updated>2018-07-15T09:23:22.375Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、实验环境"><a href="#一、实验环境" class="headerlink" title="一、实验环境"></a>一、实验环境</h2><p>主机：Ubuntu16.04<br>目标机：docker容器<br><strong>说明：</strong>在主机Ubuntu16.04中安装docker，并虚拟出一台Ubuntu容器，将该容器作为要远程访问的目标机</p><h2 id="二、实现过程"><a href="#二、实现过程" class="headerlink" title="二、实现过程"></a>二、实现过程</h2><p>1.在docker容器中安装vnc4server，并启动vnc4server服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apt-get update</span><br><span class="line"></span><br><span class="line">apt-get install vnc4server</span><br><span class="line"></span><br><span class="line">apt-get install net-tools  //安装网络工具，用于查看容器的IP地址</span><br><span class="line"></span><br><span class="line">vnc4server  //这里会提示输入密码，要记住</span><br></pre></td></tr></table></figure><p>红框可以看出启动2号桌面服务：<br><img src="http://img.blog.csdn.net/20170522210516561?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="红框可以看出启动2号桌面服务"></p><p>2.在主机Ubuntu（或centOS7）中安装并配置noVNC：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install git</span><br><span class="line">git clone https://github.com/kanaka/noVNC</span><br><span class="line">cd noVNC</span><br><span class="line"></span><br><span class="line">./utils/launch.sh --vnc 172.17.0.2:5901  </span><br><span class="line">//172.17.0.2：为目标机docker容器的IP地址。      </span><br><span class="line">//5901：为目标机启动vnc4server时启动的1号服务</span><br><span class="line"></span><br><span class="line">vi vnc_token  //新建一个文件，写入要访问的目标机的相关内容，格式为：           目标机名称: IP:端口号</span><br><span class="line"></span><br><span class="line">utils/websockify/websockify.py --web=./ --target-config vnc_tokens 6080    //运行上一步新建的内容。  **注意：运行该命令的终端不能关闭**</span><br></pre></td></tr></table></figure></p><p>执行上述最后一条命令后结果（要切换到noVNC目录下执行）：<br><img src="http://img.blog.csdn.net/20170522210642779?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="运行结果"></p><p>3.测试网站：<br><a href="http://192.168.43.227:6080/vnc_auto.html?websockify/?token=host1" target="_blank" rel="noopener">http://192.168.43.227:6080/vnc_auto.html?websockify/?token=host1</a>  </p><p>说明：192.168.43.227：为主机Ubuntu的IP地址<br>            host1：为vnc_token文件中写入的目标机名称<br>测试结果：<br><img src="http://img.blog.csdn.net/20170522210843673?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="测试结果"></p><p><strong>vnc_tokens文件中内容格式：</strong><br><img src="http://img.blog.csdn.net/20170522210943220?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="vnc_tokens文件"></p><p>4.后续需求说明<br>若需要去掉用户登录后输入密码的界面，需要修改以下部分：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vnc_auto.html文件中:</span><br><span class="line"></span><br><span class="line">form.innerHTML += &apos;&lt;input type=password size=10 id=&quot;password_input&quot; class=&quot;noVNC_status&quot; value=&quot;123456&quot;&gt;&apos;;</span><br><span class="line">form.onsubmit = true;</span><br></pre></td></tr></table></figure><p>红框内为修改部分：<br><img src="http://img.blog.csdn.net/20170522211347066?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="修改"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">core/rbf.js文件中:</span><br><span class="line"></span><br><span class="line">this._rfb_password=&apos;123456&apos;;   //123456代表上面启动vnc4server时输入的密码</span><br></pre></td></tr></table></figure><p>红框内为修改部分：<br><img src="http://img.blog.csdn.net/20170522211450992?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="修改"></p><blockquote><h4 id="说明：所有源码已上传到笔者GitHub上，欢迎follow、star。感谢！！！"><a href="#说明：所有源码已上传到笔者GitHub上，欢迎follow、star。感谢！！！" class="headerlink" title="说明：所有源码已上传到笔者GitHub上，欢迎follow、star。感谢！！！"></a>说明：所有源码已上传到笔者<strong><a href="https://github.com/amateur-RD" target="_blank" rel="noopener">GitHub</a></strong>上，欢迎follow、star。感谢！！！</h4></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、实验环境&quot;&gt;&lt;a href=&quot;#一、实验环境&quot; class=&quot;headerlink&quot; title=&quot;一、实验环境&quot;&gt;&lt;/a&gt;一、实验环境&lt;/h2&gt;&lt;p&gt;主机：Ubuntu16.04&lt;br&gt;目标机：docker容器&lt;br&gt;&lt;strong&gt;说明：&lt;/strong&gt;
      
    
    </summary>
    
      <category term="云计算" scheme="https://amateur-rd.github.io/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="Docker" scheme="https://amateur-rd.github.io/tags/Docker/"/>
    
      <category term="noVNC" scheme="https://amateur-rd.github.io/tags/noVNC/"/>
    
      <category term="远程桌面" scheme="https://amateur-rd.github.io/tags/%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/"/>
    
      <category term="ubuntu" scheme="https://amateur-rd.github.io/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://amateur-rd.github.io/2018/07/14/hello-world/"/>
    <id>https://amateur-rd.github.io/2018/07/14/hello-world/</id>
    <published>2018-07-14T03:26:35.921Z</published>
    <updated>2018-07-15T09:27:11.824Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="杂七杂八" scheme="https://amateur-rd.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"/>
    
    
      <category term="hexo" scheme="https://amateur-rd.github.io/tags/hexo/"/>
    
  </entry>
  
</feed>
