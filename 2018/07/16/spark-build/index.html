<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><title>编译spark源码的方法，及编译、案例测试问题总结 | Young Cheng</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="Java, 大数据, Hadoop, Spark, Hive, HBase, 数据库"><meta name="description" content="个人博客，用于分享一些在日常学习工作甚至于生活中遇到的一些比较有趣的东西。七荤八素，胡言乱语，望各位看官见谅。"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="https://amateur-rd.github.io/2018/07/16/spark-build/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="Young Blog"><link rel="stylesheet" href="/scss/views/page/post.css"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/img/loader.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="Young Blog" alt="Young Blog"><img src="/img/logo-text-white.png" alt="Young Blog"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1531845917832&di=918b188173037885058ca4098fd9b7ec&imgtype=0&src=http%3A%2F%2Fwww.36dsj.com%2Fwp-content%2Fuploads%2F2016%2F07%2F4221.jpg" alt="编译spark源码的方法，及编译、案例测试问题总结"></div><header class="post__info"><h1 class="post__title">编译spark源码的方法，及编译、案例测试问题总结</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/">Young</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2018-07-16</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/spark/">Spark</a></li><li class="mark__item"><a href="/tags/spark源码编译/">Spark源码编译</a></li><li class="mark__item"><a href="/tags/sparkpi/">Sparkpi</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><h2 id="一、编译spark方法"><a href="#一、编译spark方法" class="headerlink" title="一、编译spark方法"></a>一、编译spark方法</h2><p>1.编译环境<br>首先，需要安装jdk、maven，相关安装教程请参考：<a href="http://blog.csdn.net/u012829611/article/details/77651855" target="_blank" rel="noopener">http://blog.csdn.net/u012829611/article/details/77651855</a><br><a href="http://blog.csdn.net/u012829611/article/details/77678609" target="_blank" rel="noopener">http://blog.csdn.net/u012829611/article/details/77678609</a><br>笔者安装的jdk1.7、maven3.3.9.<br>然后，在官网下载spark源码（<a href="http://spark.apache.org/downloads.html），我这里选择的版本是spark-1.6.2.tgz" target="_blank" rel="noopener">http://spark.apache.org/downloads.html），我这里选择的版本是spark-1.6.2.tgz</a><br>把源码包解压：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost soft-cy]# tar -zxvf spark-1.6.2.tgz</span><br><span class="line">[root@localhost soft-cy]# cd spark-1.6.2</span><br></pre></td></tr></table></figure><p>2.两种编译方法<br>①用build/mvn 来编译（采用）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost spark-1.6.2]# build/mvn -Pyarn -Phadoop-2.7 -Dhadoop.version=2.7.3 -DskipTests clean package</span><br></pre></td></tr></table></figure><p>（-Pyarn 提供yarn支持 ，—Phadoop-2.7 提供Hadoop支持，并且指定hadoop的版本2.7.3）<br><img src="http://img.blog.csdn.net/20170901154034940?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>编译完成后，你会发现在assembly/target/scala-2.10目录下面有一个spark-assembly-1.6.2-hadoop2.7.3.jar包，这个就是编译的结果。</p><p>②用make-distributed 脚本来编译</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost spark-1.6.2]# ./make-distribution.sh --name spark-1.6.2 --skip-java-test --tgz -Pyarn -Dhadoop.version=2.7.3 -Phive -Phive-thriftserver</span><br></pre></td></tr></table></figure><p>编译完源代码后，虽然直接用编译后的目录再加以配置就可以运行spark，但是这时目录很庞大，部署起来很不方便，所以需要生成部署包。生成在部署包位于根目录下，文件名类似于 spark–bin-spark-1.6.2.tgz 。</p><h2 id="二、编译遇到问题总结"><a href="#二、编译遇到问题总结" class="headerlink" title="二、编译遇到问题总结"></a>二、编译遇到问题总结</h2><p>1.依赖包下载不下来的问题<br>如下图，显示一些相关依赖包下载不下来，即downloading过程中停止<br><img src="http://img.blog.csdn.net/20170901154201422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>【解决方法】：手动下载相关依赖包，并放到指定目录下即可。<br>以上图中第一个依赖包为例Downloading：<a href="https://repo1.maven.org/maven2/org/apache/curator/curator-test/2.4.0/curator-test-2.4.0.jar" target="_blank" rel="noopener">https://repo1.maven.org/maven2/org/apache/curator/curator-test/2.4.0/curator-test-2.4.0.jar</a><br>具体下载方法如下：从上面下载链接中可以看出依赖包存放的目录（/root/.m2/repository/org/apache/curator/curator-test/2.4.0），上面链接中加粗的部分。因此，直接cd到相应目录，wget即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# cd /root/.m2/repository/org/apache/curator/curator-test/2.4.0</span><br><span class="line">[root@localhost 2.4.0]# wget https://repo1.maven.org/maven2/org/apache/curator/curator-test/2.4.0/curator-test-2.4.0.jar</span><br></pre></td></tr></table></figure><p><strong>注</strong>：用maven进行编译时，下载的相关依赖包都放在maven库中，maven库的目录为：/root/.m2/repository</p><p>2.通过编辑pom.xml文件，注释相应的module，可以编译时跳过相应的Project，这样可以方便调试。</p><p><img src="http://img.blog.csdn.net/20170901154321442?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>3.使用第二种方法编译时，会报如下错：</p><p><img src="http://img.blog.csdn.net/20170901154336182?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>解决方法：编辑make-distribution.sh文件，注释掉下图中阴影部分，保存即可。</p><p><img src="http://img.blog.csdn.net/20170901154346881?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>参考文档：<br><a href="http://blog.csdn.net/yanran1991326/article/details/46506595" target="_blank" rel="noopener">http://blog.csdn.net/yanran1991326/article/details/46506595</a><br><a href="http://blog.csdn.net/ouyangyanlan/article/details/52355350" target="_blank" rel="noopener">http://blog.csdn.net/ouyangyanlan/article/details/52355350</a></p><h2 id="三、案例测试问题"><a href="#三、案例测试问题" class="headerlink" title="三、案例测试问题"></a>三、案例测试问题</h2><p>spark编译成功后，cd到 spark1.6.2/bin 目录下，运行 spark-shell 命令启动spark，进入scala命令模式。运行案例测试，输入 sc.parallelize(1 to 1000).count() 命令，会报下图中错误：</p><p><img src="http://img.blog.csdn.net/20170901154511668?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 spark-1.6.2]# cd bin/</span><br><span class="line">[root@localhost bin]# spark-shell</span><br><span class="line">scala&gt; sc.parallelize(1 to 1000).count()</span><br></pre></td></tr></table></figure><p></p><p>错误信息：“org.xerial.snappy.SnappyError: [FAILED_TO_LOAD_NATIVE_LIBRARY] no native library is found for os.name=Linux and os.arch=sw”。表示：snappy不支持Linux-sw操作系统。<br>解决方法：spark默认的解压缩工具为snappy，查看官网及github上，发现spark可选解压缩工具有三种lz4、lzf、snappy，于是可将spark默认的解压缩工具改为lzf。<br>官网：<a href="https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties</a><br>github：<a href="https://github.com/xerial/snappy-java/issues/178" target="_blank" rel="noopener">https://github.com/xerial/snappy-java/issues/178</a></p><p><img src="http://img.blog.csdn.net/20170901154537249?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>具体执行过程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 spark-1.6.2]# cd conf/</span><br><span class="line">[root@node1 conf]# cp spark-defaults.conf.template spark-defaults.conf</span><br><span class="line">[root@node1 conf]# vim spark-defaults.conf</span><br></pre></td></tr></table></figure><p>在最后添加命令 <code>spark.io.compression.codec lzf</code></p><p><img src="http://img.blog.csdn.net/20170901154552027?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>添加命令后，保存退出，重新启动spark，运行案例测试，结果显示成功。</p><p>案例1：统计整数个数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost bin]# spark-shell</span><br></pre></td></tr></table></figure><p><img src="http://img.blog.csdn.net/20170901172645841?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; sc.parallelize(1 to 1000).count()</span><br></pre></td></tr></table></figure><p>运行可以看到，结果显示 res0: Long = 1000 表示成功！</p><p><img src="http://img.blog.csdn.net/20170901154649633?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>案例2：计算pi的值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost bin]# run-example SparkPi</span><br></pre></td></tr></table></figure><p><img src="http://img.blog.csdn.net/20170901154730977?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p>运行可以看到，结果显示 Pi is roughly 3.14552 表示成功！</p><p><img src="http://img.blog.csdn.net/20170901154738840?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgyOTYxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><blockquote><p>参考文档：<a href="https://github.com/xerial/snappy-java/issues/178" target="_blank" rel="noopener">https://github.com/xerial/snappy-java/issues/178</a></p></blockquote><div class="post-announce">感谢您的阅读，本文由 <a href="https://amateur-rd.github.io">Young Blog</a> 版权所有。如若转载，请注明出处：Young Blog（<a href="https://amateur-rd.github.io/2018/07/16/spark-build/">https://amateur-rd.github.io/2018/07/16/spark-build/</a>）</div><div class="post__prevs"><div class="post__prev"><a href="/2018/07/15/git/" title="git命令上传本地文件到GitHub"><i class="iconfont icon-prev"></i>git命令上传本地文件到GitHub</a></div><div class="post__prev post__prev--right"></div></div></div></article></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">个人博客，用于分享一些在日常学习工作甚至于生活中遇到的一些比较有趣的东西。七荤八素，胡言乱语，望各位看官见谅。</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/杂七杂八/">杂七杂八</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/云计算/">云计算</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Linux/">Linux</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/BigData/">BigData</a><span class="block-list-count">1</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2018/07/16/spark-build/" title="编译spark源码的方法，及编译、案例测试问题总结"><div class="item__cover"><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1531845917832&di=918b188173037885058ca4098fd9b7ec&imgtype=0&src=http%3A%2F%2Fwww.36dsj.com%2Fwp-content%2Fuploads%2F2016%2F07%2F4221.jpg" alt="编译spark源码的方法，及编译、案例测试问题总结"></div><div class="item__info"><h3 class="item__title">编译spark源码的方法，及编译、案例测试问题总结</h3><span class="item__text">2018-07-16</span></div></a></li><li class="latest-post-item"><a href="/2018/07/15/git/" title="git命令上传本地文件到GitHub"><div class="item__cover"><img src="http://dn-linuxcn.qbox.me/data/attachment/album/201504/08/211202zy698mmzmm3v33q9.png" alt="git命令上传本地文件到GitHub"></div><div class="item__info"><h3 class="item__title">git命令上传本地文件到GitHub</h3><span class="item__text">2018-07-15</span></div></a></li><li class="latest-post-item"><a href="/2018/07/15/noVNC-Docker/" title="noVNC实现远程访问Docker容器桌面"><div class="item__cover"><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1531654612756&di=4987a2d0702d628a8d400043a375a459&imgtype=0&src=http%3A%2F%2Ficarephone.sqeven.me%2Fattachment%2F1511315699728.jpg" alt="noVNC实现远程访问Docker容器桌面"></div><div class="item__info"><h3 class="item__title">noVNC实现远程访问Docker容器桌面</h3><span class="item__text">2018-07-15</span></div></a></li><li class="latest-post-item"><a href="/2018/07/14/hello-world/" title="Hello World"><div class="item__cover"><img src="http://oxnuwmm3w.bkt.clouddn.com/hello-world.jpeg" alt="Hello World"></div><div class="item__info"><h3 class="item__title">Hello World</h3><span class="item__text">2018-07-14</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/Docker/">Docker</a></li><li class="tag-item"><a class="tag-link" href="/tags/git/">git</a></li><li class="tag-item"><a class="tag-link" href="/tags/github/">github</a></li><li class="tag-item"><a class="tag-link" href="/tags/hexo/">hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/linux/">linux</a></li><li class="tag-item"><a class="tag-link" href="/tags/noVNC/">noVNC</a></li><li class="tag-item"><a class="tag-link" href="/tags/spark/">spark</a></li><li class="tag-item"><a class="tag-link" href="/tags/sparkpi/">sparkpi</a></li><li class="tag-item"><a class="tag-link" href="/tags/spark源码编译/">spark源码编译</a></li><li class="tag-item"><a class="tag-link" href="/tags/ubuntu/">ubuntu</a></li><li class="tag-item"><a class="tag-link" href="/tags/远程桌面/">远程桌面</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的个人博客，主要用于记录和分享日常学习、生活及工作的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Nanjing, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>chengy2016@163.com</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="https://blog.csdn.net/u012829611" title="CSDN" target="_blank">CSDN</a></li><li class="list-item"><a href="https://www.jianshu.com/p/4eaddcbe4d12" title="hexo博客搭建方法" target="_blank">搭建方法</a></li><li class="list-item"><a href="https://github.com/Mrminfive/hexo-theme-skapp" title="hexo-theme-skapp" target="_blank">Skapp</a></li><li class="list-item"><a href="https://hexo.io/" title="Blog Framework" target="_blank">Hexo</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© 2018 <a href="https://github.com/Mrminfive" target="_blank">Chay</a> from <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/amateur-RD" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="chengy2016@163.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li><li class="social-network__item"><a href="/atom.xml" target="_blank" title="rss"><i class="iconfont icon-rss"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script></body></html>